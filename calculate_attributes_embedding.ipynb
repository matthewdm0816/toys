{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| clip.available_models(): ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets, torch, transformers\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "import logging, colorama\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "log_format = (\n",
    "    colorama.Fore.MAGENTA\n",
    "    + \"[%(asctime)s %(name)s %(levelname)s] \"\n",
    "    + colorama.Fore.WHITE\n",
    "    + \"%(message)s\"\n",
    ")\n",
    "import clip\n",
    "ic(clip.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| vinvl_datasets: {'train': Dataset({\n",
      "                        features: ['attention_mask', 'image_id', 'input_ids', 'labels', 'multiple_labels', 'question', 'question_id', 'question_type', 'tag_attention_mask', 'tag_ids', 'tags', 'token_type_ids'],\n",
      "                        num_rows: 443757\n",
      "                    }),\n",
      "                     'val': Dataset({\n",
      "                        features: ['attention_mask', 'image_id', 'input_ids', 'labels', 'multiple_labels', 'question', 'question_id', 'question_type', 'tag_attention_mask', 'tag_ids', 'tags', 'token_type_ids'],\n",
      "                        num_rows: 214354\n",
      "                    })}\n",
      "ic| vinvl_datasets[\"train\"][\"tags\"][0]: ('broccoli container almond meat container fruit fruit slice container almond '\n",
      "                                         'potato muffin fruit bowl almond pineapple box tomato plastic fruit')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'broccoli container almond meat container fruit fruit slice container almond potato muffin fruit bowl almond pineapple box tomato plastic fruit'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vinvl_path = '/home/yangliu/data/vqav2/processed_tokenized_separate_top3k_new'\n",
    "vinvl_datasets = datasets.load_from_disk(vinvl_path)\n",
    "ic(vinvl_datasets)\n",
    "ic(vinvl_datasets[\"train\"][\"tags\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tags_words[:10]: ['couple',\n",
      "                      'breakfast',\n",
      "                      'moon',\n",
      "                      'lounge',\n",
      "                      'suitcase',\n",
      "                      'french',\n",
      "                      'tissue',\n",
      "                      'pajama',\n",
      "                      'cooking',\n",
      "                      'lamb']\n",
      "ic| len(tags_words): 1297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all tags words\n",
    "tags_words = []\n",
    "for split in vinvl_datasets.keys():\n",
    "    for tag in vinvl_datasets[split][\"tags\"]:\n",
    "        tags_words.extend(tag.split(\" \"))\n",
    "# for tag in vinvl_datasets[\"train\"][\"tags\"]:\n",
    "#     tags_words.extend(tag.split(\" \"))\n",
    "\n",
    "tags_words = list(set(tags_words))\n",
    "# Show some of the tags\n",
    "ic(tags_words[:10])\n",
    "ic(len(tags_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pot basket bagel bowl ceiling table lid pot container countertop container person spoon pot spoon spoon bottle vase pot paper spoon kitchen pot donut basket person napkin paper lid pot urn bread basket bread cookie spoon food countertop plate lid pot ceiling light lamp lid bread pot person\n"
     ]
    }
   ],
   "source": [
    "# Find 'urn' in all tags\n",
    "for tag in vinvl_datasets[\"train\"][\"tags\"]:\n",
    "    if \"urn\" in tag.split(\" \"):\n",
    "        print(tag)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "    \n",
    "    def __getattr__(self, key):\n",
    "        return self.__getitem__(key)\n",
    "\n",
    "    def purge(self):\n",
    "        r\"\"\"converts all sub-elements into ObjectDict\n",
    "        \"\"\"\n",
    "        for k, v in self.items():\n",
    "            if type(v) == dict:\n",
    "                res = ObjectDict()\n",
    "                res.update(v)\n",
    "                res.purge()\n",
    "                self[k] = res\n",
    "\n",
    "opt = ObjectDict()\n",
    "opt.model_type = \"clip\"\n",
    "opt.answer_bs = 16\n",
    "opt.save_path = '../bert-vqa/a2v_rn50_union.pkl' # dummy\n",
    "opt.lbl2idx_path = '~/data/vqav2/lbl2idx_separate_top3k.pkl'\n",
    "tags = sorted(tags_words)\n",
    "device = \"cuda:3\"\n",
    "opt.model_type = 'RN50x16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| vision_layers: (6, 8, 18, 8)\n",
      "    vision_width: 96\n",
      "    output_width: 12\n",
      "    image_resolution: 384\n",
      "100%|██████████| 82/82 [00:01<00:00, 61.96it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logging.info(\"Generating Tags Embeddings...\")\n",
    "    \n",
    "    model, preprocess = clip.load(opt.model_type, device=device)\n",
    "    embedded_tags = None\n",
    "    for idx in tqdm(range(math.ceil(len(tags) / opt.answer_bs))):\n",
    "        answers_chunk = tags[idx * opt.answer_bs : (idx + 1) * opt.answer_bs]\n",
    "        answers_tok = clip.tokenize(\n",
    "            answers_chunk,\n",
    "        ).to(device)\n",
    "        text_feature = model.encode_text(answers_tok)\n",
    "        if embedded_tags is None:\n",
    "            embedded_tags = text_feature.detach().cpu()  # take first token outputs\n",
    "        else:\n",
    "            embedded_tags = torch.cat((embedded_tags, text_feature.detach().cpu()), dim=0)\n",
    "embedded_tags = {\n",
    "    tag: embedding.numpy() for tag, embedding in zip(tags, embedded_tags)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| vision_layers: (6, 8, 18, 8)\n",
      "    vision_width: 96\n",
      "    output_width: 12\n",
      "    image_resolution: 384\n",
      "100%|██████████| 196/196 [00:03<00:00, 58.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(os.path.expanduser(opt.lbl2idx_path), \"rb\") as f:\n",
    "    lbl2idx, idx2lbl = pickle.load(f)\n",
    "answers = [idx2lbl[idx] for idx in sorted(idx2lbl.keys())]\n",
    "with torch.no_grad():\n",
    "    logging.info(\"Generating Words Embeddings...\")\n",
    "    \n",
    "    model, preprocess = clip.load(opt.model_type, device=device)\n",
    "    embedded_answers = None\n",
    "    for idx in tqdm(range(math.ceil(len(answers) / opt.answer_bs))):\n",
    "        answers_chunk = answers[idx * opt.answer_bs : (idx + 1) * opt.answer_bs]\n",
    "        answers_tok = clip.tokenize(\n",
    "            answers_chunk,\n",
    "        ).to(device)\n",
    "        text_feature = model.encode_text(answers_tok)\n",
    "        if embedded_answers is None:\n",
    "            embedded_answers = text_feature.detach().cpu()  # take first token outputs\n",
    "        else:\n",
    "            embedded_answers = torch.cat((embedded_answers, text_feature.detach().cpu()), dim=0)\n",
    "embedded_answers = {\n",
    "    answer: embedding.numpy() for answer, embedding in zip(answers, embedded_answers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(answers): 3130\n",
      "ic| uncommon_keys[:10]: ['ad',\n",
      "                         'aircraft',\n",
      "                         'alarm',\n",
      "                         'alley',\n",
      "                         'almond',\n",
      "                         'ankle',\n",
      "                         'appliance',\n",
      "                         'aquarium',\n",
      "                         'archway',\n",
      "                         'area']\n",
      "    common_keys[:10]: ['cupcake',\n",
      "                       'couple',\n",
      "                       'vest',\n",
      "                       'breakfast',\n",
      "                       'moon',\n",
      "                       'teapot',\n",
      "                       'coconut',\n",
      "                       'surfing',\n",
      "                       'cargo',\n",
      "                       'suitcase']\n",
      "ic| len(uncommon_keys): 450, len(common_keys): 847\n",
      "ic| torch.norm(torch.from_numpy(embedded_tags[\"apple\"]) - embedded_answers[\"apple\"]): tensor(0., dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show common and diffenrent words\n",
    "ic(len(answers))\n",
    "common_keys = list(set(embedded_tags.keys()) & set(embedded_answers.keys()))\n",
    "uncommon_keys = list(set(embedded_tags.keys()) - set(embedded_answers.keys()))\n",
    "uncommon_keys = sorted(uncommon_keys)\n",
    "ic(uncommon_keys[:10], common_keys[:10])\n",
    "ic(len(uncommon_keys), len(common_keys))\n",
    "ic(torch.norm(torch.from_numpy(embedded_tags[\"apple\"]) - embedded_answers[\"apple\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| embedded_diff.shape: torch.Size([450, 768])\n",
      "ic| embedded_answers_base.shape: torch.Size([3130, 768])\n",
      "ic| embedded_union.shape: torch.Size([3580, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3580, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge into one embedding\n",
    "# embedded_a2v = torch.from_numpy(embedded_a2v)\n",
    "embedded_diff = torch.stack([torch.from_numpy(embedded_tags[uncommon_key]) for uncommon_key in uncommon_keys])\n",
    "embedded_answers_base = torch.stack([torch.from_numpy(embedded_answers[idx2lbl[idx]]) for idx in sorted(idx2lbl.keys())])\n",
    "# unk_embedding = embedded_answers_base[-1:]\n",
    "ic(embedded_diff.shape)\n",
    "ic(embedded_answers_base.shape)\n",
    "# Keep UNK the last one\n",
    "# embedded_union = torch.cat([embedded_answers_base[:-1], embedded_diff, unk_embedding], dim=0)\n",
    "embedded_union = torch.cat([embedded_answers_base, embedded_diff], dim=0)\n",
    "ic(embedded_union.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| idx2lbl_union[3333]: 'lampshade'\n",
      "ic| idx2lbl_union[3577]: 'wrist'\n",
      "    lbl2idx_union[idx2lbl_union[3577]]: 3577\n",
      "ic| lbl2idx_union[\"UNK\"]: 3129\n",
      "    idx2lbl_union[lbl2idx_union[\"UNK\"]]: 'UNK'\n",
      "ic| lbl2idx_union[\"baseline\"]: 3153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3153"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge pointers (lbl2idx and idx2lbl)\n",
    "lbl2idx_union = {**lbl2idx, **{uncommon_key: len(lbl2idx) + i for i, uncommon_key in enumerate(sorted(uncommon_keys))}}\n",
    "# Keep UNK the last one\n",
    "# lbl2idx_union[\"UNK\"] = len(lbl2idx_union) - 1 \n",
    "idx2lbl_union = {idx: lbl for lbl, idx in lbl2idx_union.items()}\n",
    "ic(idx2lbl_union[3333])\n",
    "ic(idx2lbl_union[3577], lbl2idx_union[idx2lbl_union[3577]])\n",
    "ic(lbl2idx_union[\"UNK\"], idx2lbl_union[lbl2idx_union[\"UNK\"]])\n",
    "ic(lbl2idx_union[\"baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged embeddings and pointers\n",
    "midfix = opt.model_type.replace('/', '_')\n",
    "with open(os.path.expanduser(f'~/data/bert-vqa/a2v_{midfix}.pt'), \"wb\") as f:\n",
    "    torch.save(embedded_answers_base, f)\n",
    "with open(os.path.expanduser(f'~/data/bert-vqa/a2v_{midfix}_union.pt'), \"wb\") as f:\n",
    "    torch.save(embedded_union, f)\n",
    "with open(os.path.expanduser(f'~/data/bert-vqa/lbl2idx_{midfix}_union.pkl'), \"wb\") as f:\n",
    "    pickle.dump((lbl2idx_union, idx2lbl_union), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embeddings\n",
    "embeddings_old = torch.load(os.path.expanduser('~/data/bert-vqa/a2v_clip_top3k.pt'))\n",
    "embeddings_new = torch.load(os.path.expanduser('~/data/bert-vqa/a2v_rn50_union.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| embeddings_old.shape: torch.Size([3129, 1024])\n",
      "    embeddings_old.dtype: torch.float32\n",
      "ic| embeddings_new.shape: torch.Size([3579, 1024])\n",
      "    embeddings_new.dtype: torch.float16\n",
      "ic| torch.norm(embeddings_old[:N] - embeddings_new[:N], dim=-1).mean(): tensor(0.0191)\n",
      "ic| torch.norm(embeddings_old[:N] - embeddings_new.to(torch.float32)[:N], dim=-1).mean(): tensor(0.0191)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0191)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(embeddings_old.shape, embeddings_old.dtype)\n",
    "ic(embeddings_new.shape, embeddings_new.dtype)\n",
    "N = 100\n",
    "ic(torch.norm(embeddings_old[:N] - embeddings_new[:N], dim=-1).mean())\n",
    "ic(torch.norm(embeddings_old[:N] - embeddings_new.to(torch.float32)[:N], dim=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(idx2lbl.keys()) == list(range(len(idx2lbl)))\n",
    "with open(os.path.expanduser('~/data/vqav2/lbl2idx_separate_top3k.pkl'), 'rb') as f:\n",
    "    lbl2idx_old, idx2lbl_old = pickle.load(f)\n",
    "\n",
    "for k, v in lbl2idx_old.items():\n",
    "    assert lbl2idx_old[k] == lbl2idx_union[k]\n",
    "\n",
    "for k, v in idx2lbl_old.items():\n",
    "    assert idx2lbl_old[k] == idx2lbl_union[k], f\"idx2lbl_old[{k}] = {idx2lbl_old[k]}, idx2lbl_union[{k}] = {idx2lbl_union[k]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| idx2lbl_union[3129]: 'UNK', lbl2idx_union[\"UNK\"]: 3129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('UNK', 3129)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ic(idx2lbl_union[3129],lbl2idx_union[\"UNK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a006c967ef34b0258bd9928363b5824b947802414e151cf95b514e3984b34a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('k3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
