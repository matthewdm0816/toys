{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets, torch, transformers\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "import logging, colorama\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "log_format = (\n",
    "    colorama.Fore.MAGENTA\n",
    "    + \"[%(asctime)s %(name)s %(levelname)s] \"\n",
    "    + colorama.Fore.WHITE\n",
    "    + \"%(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vinvl_path = '/home/yangliu/data/vqav2/processed_tokenized_separate_top3k'\n",
    "vinvl_datasets = datasets.load_from_disk(vinvl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'image_id', 'input_ids', 'labels', 'multiple_labels', 'question_type', 'tag_attention_mask', 'tag_ids', 'tags', 'token_type_ids'],\n",
       "        num_rows: 443757\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['attention_mask', 'image_id', 'input_ids', 'labels', 'multiple_labels', 'question_type', 'tag_attention_mask', 'tag_ids', 'tags', 'token_type_ids'],\n",
       "        num_rows: 214354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vinvl_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'broccoli container almond meat container fruit fruit slice container almond potato muffin fruit bowl almond pineapple box tomato plastic fruit'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vinvl_datasets[\"train\"][\"tags\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tags_words[:10]: ['mat',\n",
      "                      'bridle',\n",
      "                      'watermelon',\n",
      "                      'grapefruit',\n",
      "                      'park',\n",
      "                      'fire',\n",
      "                      'column',\n",
      "                      'spoke',\n",
      "                      'hamburger',\n",
      "                      'milk']\n",
      "ic| len(tags_words): 1293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all tags words\n",
    "tags_words = []\n",
    "for tag in vinvl_datasets[\"train\"][\"tags\"]:\n",
    "    tags_words.extend(tag.split(\" \"))\n",
    "tags_words = list(set(tags_words))\n",
    "# Show some of the tags\n",
    "ic(tags_words[:10])\n",
    "ic(len(tags_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pot basket bagel bowl ceiling table lid pot container countertop container person spoon pot spoon spoon bottle vase pot paper spoon kitchen pot donut basket person napkin paper lid pot urn bread basket bread cookie spoon food countertop plate lid pot ceiling light lamp lid bread pot person\n"
     ]
    }
   ],
   "source": [
    "# Find 'urn' in all tags\n",
    "for tag in vinvl_datasets[\"train\"][\"tags\"]:\n",
    "    if \"urn\" in tag.split(\" \"):\n",
    "        print(tag)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "    \n",
    "    def __getattr__(self, key):\n",
    "        return self.__getitem__(key)\n",
    "\n",
    "    def purge(self):\n",
    "        r\"\"\"converts all sub-elements into ObjectDict\n",
    "        \"\"\"\n",
    "        for k, v in self.items():\n",
    "            if type(v) == dict:\n",
    "                res = ObjectDict()\n",
    "                res.update(v)\n",
    "                res.purge()\n",
    "                self[k] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:49<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = ObjectDict()\n",
    "opt.model_type = \"clip\"\n",
    "opt.answer_bs = 16\n",
    "opt.save_path = '../bert-vqa/t2v_clip.pt'\n",
    "\n",
    "answers = tags_words\n",
    "device = \"cpu\"\n",
    "\n",
    "import clip\n",
    "with torch.no_grad():\n",
    "    logging.info(\"Generating Answer Embeddings...\")\n",
    "    \n",
    "    model, preprocess = clip.load(\"RN50\", device=device)\n",
    "    embedded = None\n",
    "    for idx in tqdm(range(math.ceil(len(answers) / opt.answer_bs))):\n",
    "        answers_chunk = answers[idx * opt.answer_bs : (idx + 1) * opt.answer_bs]\n",
    "        answers_tok = clip.tokenize(\n",
    "            answers_chunk,\n",
    "        ).to(device)\n",
    "        text_feature = model.encode_text(answers_tok)\n",
    "        if embedded is None:\n",
    "            embedded = text_feature.detach().cpu()  # take first token outputs\n",
    "        else:\n",
    "            embedded = torch.cat((embedded, text_feature.detach().cpu()), dim=0)\n",
    "        # ic(embedded.shape)\n",
    "\n",
    "embedded = {tag: embedding.numpy() for tag, embedding in zip(answers, embedded)}\n",
    "# Save a tag-to-embedding mapping\n",
    "logging.info(\"Saving Word Embeddings...\")\n",
    "with open(opt.save_path, \"wb\") as f:\n",
    "    torch.save(embedded, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| embedded[\"apple\"].shape: (1024,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved embeddings\n",
    "with open(opt.save_path, \"rb\") as f:\n",
    "    embedded = torch.load(f)\n",
    "\n",
    "ic(embedded[\"apple\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a006c967ef34b0258bd9928363b5824b947802414e151cf95b514e3984b34a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('k3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
